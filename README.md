## 机器学习安全

### 对抗样本

#### 生成

* FGSM [[论文](<https://arxiv.org/abs/1412.6572>)] [[代码](<https://github.com/akshaychawla/Adversarial-Examples-in-PyTorch>)] [[解读](<https://chaoge123456.github.io/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E7%B3%BB%E5%88%97%EF%BC%9AFGSM%E5%92%8CDeepfool.html/#more>)]
* DeepFool [[论文](<https://arxiv.org/abs/1511.04599>)] [[代码](<https://github.com/LTS4/DeepFool/tree/master/Python>)] [[解读](<https://chaoge123456.github.io/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E7%B3%BB%E5%88%97%EF%BC%9AFGSM%E5%92%8CDeepfool.html/#more>)]
* Universal adversarial perturbations [[论文](<https://arxiv.org/abs/1610.08401>)] [[代码](<https://github.com/LTS4/universal>)] [[解读](<https://chaoge123456.github.io/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E7%B3%BB%E5%88%97%EF%BC%9AFGSM%E5%92%8CDeepfool.html/#more>)]
* JSMA [[论文](https://arxiv.org/abs/1511.07528)] [[代码](https://github.com/chaoge123456/MLsecurity/tree/master/blog/JSMA)] [[解读](https://chaoge123456.github.io/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E7%B3%BB%E5%88%97%EF%BC%9AJSMA%E7%9B%AE%E6%A0%87%E6%89%B0%E5%8A%A8.html/#more)]

